# Data Fusion Contest 25'. Label Craft. 33rd place

Данный репозиторий представляет из себя решение задачи классификации товаров согласно категориальному древу в рамках соревнования [Data Fusion Contest 2025. Задача 1 "Label Craft"](https://ods.ai/competitions/data-fusion2025-labelcraft).

## Содержимое репозитория:
* **/data**: папка, в которой хранятся все данные;
* **/external_data**: папка, в которой хранятся внешние данные;
* **/models**: папка, в которой хранятся модели;
* **rule-based_labeling.py**: скрипт, который размечает данные из */data/unlabeled_train.parquet* на основании правил и добавляет их в обучающую выборку;
* **dataset_extending.py**: *(Требует предварительного размещения в папку /external_data внешних данных. Ссылки указаны в скрипте!)* Скрипт, который находит во внешних данных товары с идентичными категориями из размеченной выборки и добавляет их в обучающую выборку;
* **labeling_by_retriever.py**: скрипт, который использует до-обученную модель retriever [можно использовать и предобученную версию!], рассчитывает косинусное сходство между эмбеддингами оглавлений категорий и описаний товаров, на основании порогового значения этого сходства присваивает метку товару и добавляет размеченные образцы в обучающую выборку;
* **mnb_training.py**: скрипт, который обучает векторизатор CountVectorizer и классификатор MultinomialNB и сохраняет их в папку */models*;
*  **e5_ft.py**: скрипт, который до-обучает модель [d0rj/e5-large-en-ru](https://huggingface.co/d0rj/e5-large-en-ru) и сохраняет её в папку */models/e5-large-en-ru*;
*  **run.py**: *(Требует указания именованных аргументов с расположением файла с тестовой выборкой и расположением файла для сохранения результатов!)* Скрипт, который сохраняет финальные предсказания для тестовой выборки на основании предсказаний классификатора MultinomialNB и ретривера e5;
*  **eda.ipynb**: Jupyter-ноутбук, в котором представлены образцы данных и их специфика;
*  **metadata.json**: метаданные для запуска скрипта *run.py* внутри Docker-контейнера;
*  **requirements.txt**: библиотеки с указанием их версий, которые необходимо установить в репозитории для успешного запуска скриптов;

## Подход к решению задачи

### Расширение выборки:
Качество разметки в предоставленных данных было далёким от идеального, поэтому для того, чтобы не нарушить настоящее распределение межклассовых текстовых паттернов, было 2 основных принципа:
* добавлять описания товаров только по малочисленным классам (< 20);
* добавлять не более 20-ти образцов;

### Модели:
* #### Модель retriever:
  * **Преимущество**: не требует полностью размеченных данных, показывает хорошее качество на данных, которых не было в обучающей выборке;
  * **Недостаток**: крайне требователен к качеству разметки обучающей выборки;
* #### Модель classifier:
  * **Преимущество**: если внутриклассовые текстовые паттерны единообразны (даже в случае неидеальной разметки), показывает высокий результат на локальной валидации;
  * **Недостаток**: невозможно масштабировать решение на те данные, которых не было в обучающей выборке;

### Схема обучения моделей:
* #### Модель retriever:
  * Обучающая выборка в виде триплетов:
    * query: описание товара;
    * positive: истинное оглавление класса товара;
    * negative: ложное оглавление класса товара;
  * Для каждого класса товаров отбирались до 150-ти образцов, т.е. был реализован downsampling;
  * Негативные кандидаты в количестве 10 шт. отбирались при помощи предобученной модели retriever;
  * В обучающую выборку также были добавлены следующие триплеты:
    * query: оглавление класса товара;
    * positive: оглавление истинного родительского класса по отношению к *query*;
    * negative: оглавление класса, у которого та же родительская категория, что и у *positive*;
* #### Модель classifier:
  * Приведение текстов описания товаров к нижнему регистру;
  * Векторизация с помощью CountVectorizer;
  * В качестве метки класса служила id категории;

### Схема валидации моделей:
* Стратифицированное по категориям разбиение выборки на тренировочную и валидационную в соотношении 4 к 1.
  * #### Модель retriever:
    * Метрика: cosine accuracy: **0.959**
    * *Примечание к метрике: метрика рассчитывалась в условном исполнении "macro": в валидационной выборке было ровно 10 образцов каждого класса, таким образом в метрике учитывался дисбаланс классов.*
  * #### Модель classifier:
    * Метрика: f1 macro: **0.68990**
* После найденных на этапе валидации сочетаний гиперпараметров модели заново обучались, но уже на полном наборе данных (с сохранением downsampling);

### Схема инференса:
1. Отбор с помощью модели retriever 100-та кандидатов;
2. Выбор кандидата:
   1. Выбирается предсказанный моделью classifier класс, если он есть среди кандидатов;
   2. Выбирается 1-й кандидат от retriever, если предсказанного моделью classifier класса нет среди кандидатов;

## Прочие параметры решения:
### Оборудование:
Kaggle GPU P100 (16GB VRAM)

### Время обучения retriever:
5h:11m:35s

### Финальная метрика HDA:
0.79853